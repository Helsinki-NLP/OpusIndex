# -*-makefile-*-

SHELL := bash



CSC_PROJECT := project_2000661

# job-specific settings (overwrite if necessary)
# HPC_EXTRA: additional SBATCH commands

HPC_MEM     = 4g
HPC_TIME    = 72:00
HPC_NODES   = 1
HPC_CORES   = 1
HPC_QUEUE   = small
HPC_MODULES = allas parallel git
HPC_EXTRA   =




ALLAS_CONF       := source /appl/opt/csc-cli-utils/allas-cli-utils/allas_conf -s
LOAD_STORAGE_ENV := module load allas && ${ALLAS_CONF} -k ${CSC_PROJECT}


# enable e-mail notification by setting EMAIL

WHOAMI = $(shell whoami)
ifeq ("$(WHOAMI)","tiedeman")
  EMAIL = jorg.tiedemann@helsinki.fi
endif


ifeq (${shell hostname --domain 2>/dev/null},bullx)
  HPC_HOST = puhti
endif


## scratch/work space

ifneq (${wildcard /scratch/${CSC_PROJECT}/tmp},)
  TMPDIR := /scratch/${CSC_PROJECT}/tmp
endif

TMPDIR ?= /tmp

ifdef LOCAL_SCRATCH
  TMPDIR := ${LOCAL_SCRATCH}
endif

WORKDIR ?= ${TMPDIR}

CORES    := ${shell nproc}
THREADS  ?= $(shell if [ `hostname | grep login | wc -l` -gt 0 ]; then echo 4; else echo ${CORES}; fi )
GZIP     := ${shell which pigz 2>/dev/null || echo gzip}
GZCAT    := ${GZIP} -cd
ZCAT     := gzip -cd
SORT     := sort -T ${TMPDIR} -S1G --parallel=${THREADS}
UNIQ     := ${SORT} -u
MERGE    := ${SORT} -m -u

## seems to be necessary to run with threads on HPC nodes
## (nproc is not reliable?)
ifneq (${GZIP},gzip)
  GZIP += -p ${THREADS}
endif

PARALLEL_ARGS := --max-procs 25% --pipe --keep-order -q
PARALLEL := ${shell if [ `which parallel 2>/dev/null | wc -l` -gt 0 ]; then echo 'parallel ${PARALLEL_ARGS}'; fi }




%.submit:
	echo '#!/bin/bash -l' > $@
	echo '#SBATCH -J "${@:.submit=}"' >>$@
	echo '#SBATCH -o ${@:.submit=}.out.%j' >> $@
	echo '#SBATCH -e ${@:.submit=}.err.%j' >> $@
	echo '#SBATCH --mem=${HPC_MEM}' >> $@
ifeq (${shell hostname --domain},bullx)
ifdef HPC_DISK
	echo '#SBATCH --gres=nvme:${HPC_DISK}' >> $@
endif
	echo '#SBATCH --account=${CSC_PROJECT}' >> $@
endif
ifeq (${shell hostname --domain},mahti.csc.fi)
	echo '#SBATCH --account=${CSC_PROJECT}' >> $@
endif
ifdef EMAIL
	echo '#SBATCH --mail-type=END' >> $@
	echo '#SBATCH --mail-user=${EMAIL}' >> $@
endif
	echo '#SBATCH -n ${HPC_CORES}' >> $@
	echo '#SBATCH -N ${HPC_NODES}' >> $@
	echo '#SBATCH -p ${HPC_QUEUE}' >> $@
	echo '#SBATCH -t ${HPC_TIME}:00' >> $@
	echo '${HPC_EXTRA}' >> $@
	echo 'module use -a /proj/nlpl/modules' >> $@
	echo 'module use -a /projappl/nlpl/software/modules/etc' >> $@
	for m in ${HPC_MODULES}; do \
	  echo "module load $$m" >> $@; \
	done
	echo 'module list' >> $@
	echo 'cd $${SLURM_SUBMIT_DIR:-.}' >> $@
	echo 'pwd' >> $@
	echo 'echo "Starting at `date`"' >> $@
	echo '${MAKE} -j ${HPC_CORES} ${MAKEARGS} ${@:.submit=}' >> $@
	echo 'echo "Finishing at `date`"' >> $@
	sbatch ${SBATCH_ARGS} $@
	mv $@ $@-${shell date "+%Y-%m-%d"}


%-job:
	${MAKE} HPC_CORES=4 THREADS=4 HPC_MEM=16g HPC_TIME=72:00 HPC_DISK=1000 $(@:-job=).submit

%-largejob:
	${MAKE} HPC_CORES=8 THREADS=8 HPC_MEM=32g HPC_TIME=72:00 HPC_DISK=3000 $(@:-largejob=).submit



